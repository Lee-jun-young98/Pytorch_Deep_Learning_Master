{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.autograd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjGqpZy4714tB26CT3BG4p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ox04WDq9uTnY","executionInfo":{"status":"ok","timestamp":1657785725534,"user_tz":-540,"elapsed":3754,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import torch\n","torch.set_printoptions(edgeitems=2)"]},{"cell_type":"code","source":["t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n","                    3.0, -4.0, 6.0, 13.0, 21.0])\n","t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n","                    33.9, 21.8, 48.4, 60.4, 68.4])\n","t_un = 0.1 * t_u"],"metadata":{"id":"l10GyfHhuoKD","executionInfo":{"status":"ok","timestamp":1657785786071,"user_tz":-540,"elapsed":4,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def model(t_u, w, b):\n","    return w * t_u + b"],"metadata":{"id":"yEpJmTXsu5HD","executionInfo":{"status":"ok","timestamp":1657785796257,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def loss_fn(t_p, t_c):\n","    squared_diffs = (t_p - t_c)**2\n","    return squared_diffs.mean()"],"metadata":{"id":"r2n9Z2pGu8Di","executionInfo":{"status":"ok","timestamp":1657785824149,"user_tz":-540,"elapsed":2,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["params = torch.tensor([1.0, 0.0], requires_grad=True) # 파라미터 초기화"],"metadata":{"id":"JihDKsWEvC_S","executionInfo":{"status":"ok","timestamp":1657785837652,"user_tz":-540,"elapsed":8,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["params.grad is None # pytorch에서 주로 grad의 값은 None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eq5cqJP6vGOy","executionInfo":{"status":"ok","timestamp":1657785842867,"user_tz":-540,"elapsed":439,"user":{"displayName":"이준영","userId":"14894232288140235299"}},"outputId":"3ea3fefa-313b-4b69-d683-5576c9833a6f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["loss = loss_fn(model(t_u, *params), t_c)\n","loss.backward()"],"metadata":{"id":"J-uxBweuvHZh","executionInfo":{"status":"ok","timestamp":1657785916070,"user_tz":-540,"elapsed":11,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["params.grad # grad 함수에 누적한다"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4q_AKhXvZbT","executionInfo":{"status":"ok","timestamp":1657785938862,"user_tz":-540,"elapsed":3,"user":{"displayName":"이준영","userId":"14894232288140235299"}},"outputId":"6a8d6183-430a-4937-e044-b20d506bb281"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([4517.2969,   82.6000])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["params2 = torch.tensor([2.0, 1.0], requires_grad=True)"],"metadata":{"id":"O9AYL8ynvnuy","executionInfo":{"status":"ok","timestamp":1657786041094,"user_tz":-540,"elapsed":7,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["loss2 = loss_fn(model(t_u, *params2), t_c)\n","loss2.backward()\n","params2.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUt1wEMsvymi","executionInfo":{"status":"ok","timestamp":1657786081908,"user_tz":-540,"elapsed":2,"user":{"displayName":"이준영","userId":"14894232288140235299"}},"outputId":"8edd9ecb-363e-4482-8618-13e1252e0fd8"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10502.4941,   188.2000])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# backward 호출은 미분을 말단 노드에 누적하므로 앞서 backward가 호출되었다면 손실이 다시 계산되고 backward가 다시 호출되고 \n","# 각 말단 노드의 기울기 값이 이전 반복문 수행 시 계산 되었던 기존값에 누적되어 부정확한 기울기 값이 발생\n","# 각 반복문에서 명시적으로 기울기를 0으로 초기화해야함\n","if params.grad is not None:\n","    params.grad.zero_()"],"metadata":{"id":"ULKH9bd9v-4z","executionInfo":{"status":"ok","timestamp":1657786202781,"user_tz":-540,"elapsed":5,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","    for epoch in range(1, n_epochs + 1):\n","        if params.grad is not None:\n","            params.grad.zero_()\n","\n","        t_p = model(t_u, *params)\n","        loss = loss_fn(t_p, t_c)\n","        loss.backward()\n","\n","        with torch.no_grad():\n","            params -= learning_rate * params.grad\n","\n","        if epoch % 500 == 0:\n","            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n","\n","    return params"],"metadata":{"id":"XyVnJuLawffD","executionInfo":{"status":"ok","timestamp":1657786328632,"user_tz":-540,"elapsed":4,"user":{"displayName":"이준영","userId":"14894232288140235299"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["training_loop(\n","    n_epochs = 5000,\n","    learning_rate = 1e-2,\n","    params = torch.tensor([1.0, 0.0], requires_grad = True),\n","    t_u = t_un,\n","    t_c = t_c\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uwjtoLnw-Jz","executionInfo":{"status":"ok","timestamp":1657786364694,"user_tz":-540,"elapsed":1145,"user":{"displayName":"이준영","userId":"14894232288140235299"}},"outputId":"c8a4483c-a843-4599-eadb-9e833ecac4f2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 500, Loss 7.860115\n","Epoch 1000, Loss 3.828538\n","Epoch 1500, Loss 3.092191\n","Epoch 2000, Loss 2.957698\n","Epoch 2500, Loss 2.933134\n","Epoch 3000, Loss 2.928648\n","Epoch 3500, Loss 2.927830\n","Epoch 4000, Loss 2.927679\n","Epoch 4500, Loss 2.927652\n","Epoch 5000, Loss 2.927647\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([  5.3671, -17.3012], requires_grad=True)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[""],"metadata":{"id":"KY8r-BPGxGvT"},"execution_count":null,"outputs":[]}]}